{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62667,
     "status": "ok",
     "timestamp": 1581906618847,
     "user": {
      "displayName": "Yutong Yang",
      "photoUrl": "",
      "userId": "17222437994937264492"
     },
     "user_tz": 300
    },
    "id": "CJhwBSWHd-Ms",
    "outputId": "34e4854f-83e6-48e1-b6ba-8932b3955000"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-893cd14b86ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0muploaded\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#This part has been added for you to upload the dataset diabetes.pickle from your own computer (Feb 12th)\n",
    "#Immediately hit Choose file Button after running, otherwise there will be an error message\n",
    "#If you find any error, just edit it directly but please do not forget make a copy beforehand\n",
    "#Thank you\n",
    "\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "uploaded= files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 656,
     "status": "ok",
     "timestamp": 1581867155876,
     "user": {
      "displayName": "Yutong Yang",
      "photoUrl": "",
      "userId": "17222437994937264492"
     },
     "user_tz": 300
    },
    "id": "C3ZhACX_9Wup",
    "outputId": "7f7aa524-472e-45ce-f0d2-7623f3cfec3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBLEM 1\n",
      "----------\n",
      "==================================\n",
      "==================================\n",
      "RMSE without intercept on train data - 8.58\n",
      "RMSE with intercept on train data - 3.00\n",
      "==================================\n",
      "==================================\n",
      "RMSE without intercept on test data - 18.02\n",
      "RMSE with intercept on test data - 4.80\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "print('PROBLEM 1')\n",
    "print('----------')\n",
    "def learnOLERegression(Xtrain,ytrain):\n",
    "   A=np.array(Xtrain)\n",
    "   B=np.array(ytrain)\n",
    "   At =np.transpose(A)\n",
    "   AtA=np.dot(At,A)\n",
    "   AtA_Inverse=np.linalg.inv(AtA)\n",
    "   AtA_InverseAt=np.dot(np.linalg.inv(AtA),At)\n",
    "   w=np.dot(AtA_InverseAt,B)\n",
    "   return w\n",
    "\n",
    "def testOLERegression(w,Xtest,ytest):\n",
    "    A=np.array(Xtest)\n",
    "    B=np.array(ytest)\n",
    "    wt=np.transpose(w)\n",
    "    sum=0\n",
    "    for i in range(0,np.size(A[1])):\n",
    "     wtxi=np.dot(wt,A[i])\n",
    "     yiwtxi=B[i]-wtxi\n",
    "     yiwtxi2=yiwtxi**2\n",
    "     sum=sum+yiwtxi2\n",
    "    average=sum/np.size(A)\n",
    "    rmse=math.sqrt(average)\n",
    "    return rmse\n",
    "\n",
    "Xtrain,ytrain,Xtest,ytest = pickle.load(open('diabetes.pickle','rb'),encoding='latin1')   \n",
    "# add intercept\n",
    "x1 = np.ones((len(Xtrain),1))\n",
    "x2 = np.ones((len(Xtest),1))\n",
    "\n",
    "Xtrain_i = np.concatenate((np.ones((Xtrain.shape[0],1)), Xtrain), axis=1)\n",
    "Xtest_i = np.concatenate((np.ones((Xtest.shape[0],1)), Xtest), axis=1)\n",
    "\n",
    "w = learnOLERegression(Xtrain,ytrain)\n",
    "w_i = learnOLERegression(Xtrain_i,ytrain)\n",
    "\n",
    "rmse = testOLERegression(w,Xtrain,ytrain)\n",
    "rmse_i = testOLERegression(w_i,Xtrain_i,ytrain)\n",
    "print('RMSE without intercept on train data - %.2f'%rmse)\n",
    "print('RMSE with intercept on train data - %.2f'%rmse_i)\n",
    "\n",
    "rmse = testOLERegression(w,Xtest,ytest)\n",
    "rmse_i = testOLERegression(w_i,Xtest_i,ytest)\n",
    "print('RMSE without intercept on test data - %.2f'%rmse)\n",
    "print('RMSE with intercept on test data - %.2f'%rmse_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 505,
     "status": "ok",
     "timestamp": 1581867141587,
     "user": {
      "displayName": "Yutong Yang",
      "photoUrl": "",
      "userId": "17222437994937264492"
     },
     "user_tz": 300
    },
    "id": "jTsmMq_oS1BW",
    "outputId": "4901e3cb-fa0f-472a-a316-64cf7125987c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBLEM 2\n",
      "----------\n",
      "Gradient Descent Linear Regression RMSE on train data - 3.07\n",
      "Gradient Descent Linear Regression RMSE on test data - 4.47\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "print('PROBLEM 2')\n",
    "print('----------')\n",
    "\n",
    "def regressionObjVal(w, X, y):\n",
    "  w=np.matrix(w)\n",
    "  w=w.transpose()\n",
    "  A=np.dot(X,w)\n",
    "  B=np.subtract(y,A)\n",
    "  Bt=B.transpose()\n",
    "  e=np.dot(Bt,B)\n",
    "  E=0.5*e\n",
    "  error=E[0,0]\n",
    "  print(error)\n",
    "  return error\n",
    "\n",
    "def regressionGradient(w, X, y):\n",
    "  w=np.matrix(w)\n",
    "  w=w.transpose()\n",
    "  A=X.transpose()\n",
    "  B=X\n",
    "  B1=np.dot(A,B)\n",
    "  B2=np.dot(B1,w)\n",
    "  C=np.dot(A,y)\n",
    "  D=B2-C\n",
    "  D= np.squeeze(np.asarray(D))\n",
    "  return D  \n",
    "\n",
    "def testOLERegression(w,Xtest,ytest):\n",
    "\n",
    "    A=np.array(Xtest)\n",
    "    B=np.array(ytest)\n",
    "    wt=np.transpose(w)\n",
    "    sum=0\n",
    "    for i in range(0,np.size(A[1])):\n",
    "     wtxi=np.dot(wt,A[i])\n",
    "     yiwtxi=B[i]-wtxi\n",
    "     yiwtxi2=yiwtxi**2\n",
    "     sum=sum+yiwtxi2\n",
    "    average=sum/np.size(A)\n",
    "    rmse=math.sqrt(average)\n",
    "    return rmse\n",
    "\n",
    "Xtrain,ytrain,Xtest,ytest = pickle.load(open('diabetes.pickle','rb'),encoding='latin1')   \n",
    "# add intercept\n",
    "Xtrain_i = np.concatenate((np.ones((Xtrain.shape[0],1)), Xtrain), axis=1)\n",
    "Xtest_i = np.concatenate((np.ones((Xtest.shape[0],1)), Xtest), axis=1)\n",
    "args = (Xtrain_i,ytrain)\n",
    "opts = {'maxiter' : 50000}    # Preferred value.  # I have changed this from 50 to 50000  \n",
    "w_init = np.zeros((Xtrain_i.shape[1],1))\n",
    "soln = minimize(regressionObjVal, w_init, jac=regressionGradient, args=args,method='CG', options=opts)\n",
    "w = np.transpose(np.array(soln.x))\n",
    "w = w[:,np.newaxis]\n",
    "rmse = testOLERegression(w,Xtrain_i,ytrain)\n",
    "print('Gradient Descent Linear Regression RMSE on train data - %.2f'%rmse)\n",
    "rmse = testOLERegression(w,Xtest_i,ytest)\n",
    "print('Gradient Descent Linear Regression RMSE on test data - %.2f'%rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1581885322558,
     "user": {
      "displayName": "Yutong Yang",
      "photoUrl": "",
      "userId": "17222437994937264492"
     },
     "user_tz": 300
    },
    "id": "QVCu4NLtkSWE",
    "outputId": "5926ce2a-77ec-4493-e090-236a7148e33a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBLEM 3\n",
      "----------\n",
      "[ 1.16850571  0.71176206  0.98410135 -0.54911059 -0.13181726 -0.41341988\n",
      " -0.05221272  0.16976168 -0.01645664 -0.18618108 -0.25704278  1.00102619\n",
      " -0.79012519 -0.71365544 -0.05566753  0.52563323  0.56352636  1.04666937\n",
      "  0.04938761 -0.18795813 -0.16691849  0.73758744 -1.21170854  0.29171098\n",
      "  1.02979469  0.65397903  0.33050126 -0.48668059  0.76919735 -0.6944933\n",
      "  1.35522122  1.44057828  1.47024221 -0.73117633 -0.08867003  1.56046918\n",
      " -0.66804667  0.57730486 -0.0058352   0.11870536  0.2398941   0.68116452\n",
      " -0.34205676  0.03697825 -0.34835979 -1.38626791 -0.60365128 -0.40042824\n",
      "  0.35510575 -1.11172911  1.49055186  0.19385935  1.36901134  0.19555698\n",
      " -0.80580697  0.06696253  0.08375397  0.17205729 -0.45772662 -0.79024485\n",
      " -0.16742125  0.01226365 -0.59165793 -0.47955102 -0.49259958 -0.62980498\n",
      "  0.34482687  0.80830885 -1.15268063 -0.16495998  0.04017991  1.13726473\n",
      "  0.30005169  0.74066528  0.09547864 -0.5805698  -0.36092859  0.49011372\n",
      " -0.87578922  1.51226501  1.06587997 -0.1551167  -0.42021774  0.07361545\n",
      " -0.19837352  0.33501715  0.33455798  0.25024923  0.8209529  -0.09676692\n",
      "  1.05203249  0.26084035 -0.89296668 -0.15028072 -0.96931024  0.69297393\n",
      "  0.12201861 -1.01522185 -0.3225766  -0.55987596]\n",
      "[1, 1, 1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1]\n",
      "Perceptron Accuracy on train data - 0.84\n",
      "[-1.98876638 -0.09125301 -0.10974644  0.06126027 -1.40789261 -0.58717681\n",
      "  0.29414388 -0.07390906 -1.27311646  0.57282805  0.16743072 -1.16173683\n",
      "  0.06891173 -0.07762248  0.60047871  2.04568503 -0.01160345 -0.73169116\n",
      " -0.40028078  0.88524539 -0.46331641 -0.97039166  0.37472458  0.0170288\n",
      " -0.61737274 -0.2603466   1.66745035  0.80954868 -0.44298118 -0.31674237\n",
      "  1.20304958 -0.06730146 -0.46370038 -0.0827695  -0.63145069 -0.01593336\n",
      " -0.72798577 -1.18172939 -0.49958659  0.70738049  0.18280879 -0.80292869\n",
      "  0.60590997 -0.2274906   0.84223333  0.38193978 -0.14059217 -0.0657001\n",
      "  0.18810951  1.33278864  0.41940009  0.94126879 -0.327477    0.32081033\n",
      "  0.61136174  0.35128233 -1.84451465  0.02704779  0.94554894 -0.20730157\n",
      " -0.45275757  1.12092514 -0.34200654 -1.03080639 -0.187098    0.09999979\n",
      "  1.78701442  0.63188513 -0.61022454 -0.90843938 -0.90545808  0.60658693\n",
      "  1.31013925  0.18141992 -0.63107826  0.56394674  0.44958515 -0.48598195\n",
      " -0.99685267 -1.0274055   0.75642548 -0.24411743 -0.29424415 -0.35055987\n",
      " -0.16047831  2.11376356  1.35010376 -1.19648755 -0.97945136 -0.52098213\n",
      " -0.00451878 -0.02281398  0.54619876 -0.92748605  0.021055    1.09083576\n",
      " -0.97367457  1.43878298 -0.48310634 -0.35138309]\n",
      "[-1, -1, -1, 1, -1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1]\n",
      "Perceptron Accuracy on test data - 0.84\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "print('PROBLEM 3')\n",
    "print('----------')\n",
    "def regressionObjVal(w, X, y):\n",
    "  w=np.matrix(w)\n",
    "  w=w.transpose()\n",
    "  A=np.dot(X,w)\n",
    "  B=np.subtract(y,A)\n",
    "  Bt=B.transpose()\n",
    "  e=np.dot(Bt,B)\n",
    "  E=0.5*e\n",
    "  error=E[0,0]\n",
    "  return error\n",
    "\n",
    "def regressionGradient(w, X, y):\n",
    "  w=np.matrix(w)\n",
    "  w=w.transpose()\n",
    "  A=X.transpose()\n",
    "  B=X\n",
    "  B1=np.dot(A,B)\n",
    "  B2=np.dot(B1,w)\n",
    "  C=np.dot(A,y)\n",
    "  D=B2-C\n",
    "  D= np.squeeze(np.asarray(D))\n",
    "  return D  \n",
    "\n",
    "def predictLinearModel(w,Xtest):\n",
    "    print(w)\n",
    "    y=np.dot(Xtest,w)\n",
    "    y= np.squeeze(np.asarray(y))\n",
    "    print(y)\n",
    "    ypred=[]\n",
    "    for i in y:\n",
    "      if i>=0:\n",
    "         ypred.append(1)\n",
    "      else:\n",
    "         ypred.append(-1)\n",
    "    print(ypred)\n",
    "    ypred = np.array(ypred)\n",
    "    ypred = ypred.reshape(-1, 1)\n",
    "    return ypred\n",
    "\n",
    "def evaluateLinearModel(w,Xtest,ytest):\n",
    "    ypred=predictLinearModel(w,Xtest)\n",
    "    ytest= np.squeeze(np.asarray(ytest))\n",
    "    ypred= np.squeeze(np.asarray(ypred))\n",
    "    total=len(ypred)\n",
    "    accuracy=0\n",
    "    for i in range(0,total):\n",
    "      if ytest[i]==ypred[i]:\n",
    "        accuracy=accuracy+1\n",
    "    acc= accuracy/total\n",
    "    return acc\n",
    "\n",
    "Xtrain,ytrain, Xtest, ytest = pickle.load(open('sample.pickle','rb')) \n",
    "# add intercept\n",
    "Xtrain_i = np.concatenate((np.ones((Xtrain.shape[0],1)), Xtrain), axis=1)\n",
    "Xtest_i = np.concatenate((np.ones((Xtest.shape[0],1)), Xtest), axis=1)\n",
    "args = (Xtrain_i,ytrain)\n",
    "opts = {'maxiter' : 50}    # Preferred value.    \n",
    "w_init = np.zeros((Xtrain_i.shape[1],1))\n",
    "soln = minimize(regressionObjVal, w_init, jac=regressionGradient, args=args,method='CG', options=opts)\n",
    "w = np.transpose(np.array(soln.x))\n",
    "w = w[:,np.newaxis]\n",
    "acc = evaluateLinearModel(w,Xtrain_i,ytrain)\n",
    "print('Perceptron Accuracy on train data - %.2f'%acc)\n",
    "acc = evaluateLinearModel(w,Xtest_i,ytest)\n",
    "print('Perceptron Accuracy on test data - %.2f'%acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1042,
     "status": "ok",
     "timestamp": 1581886151481,
     "user": {
      "displayName": "Yutong Yang",
      "photoUrl": "",
      "userId": "17222437994937264492"
     },
     "user_tz": 300
    },
    "id": "_Ti9ioKqwwOb",
    "outputId": "ba1eaede-61aa-457b-98ca-6436f4180bcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBLEM 4\n",
      "----------\n",
      "Logistic Regression Accuracy on train data - 0.84\n",
      "Logistic Regression Accuracy on test data - 0.86\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "print('PROBLEM 4')\n",
    "print('----------')\n",
    "\n",
    "def predictLinearModel(w,Xtest):\n",
    "    y=np.dot(Xtest,w)\n",
    "    y= np.squeeze(np.asarray(y))\n",
    "    ypred=[]\n",
    "    for i in y:\n",
    "      if i>=0:\n",
    "         ypred.append(1)\n",
    "      else:\n",
    "         ypred.append(-1)\n",
    "    ypred = np.array(ypred)\n",
    "    ypred = ypred.reshape(-1, 1)\n",
    "    return ypred\n",
    "\n",
    "def evaluateLinearModel(w,Xtest,ytest):\n",
    "    ypred=predictLinearModel(w,Xtest)\n",
    "    ytest= np.squeeze(np.asarray(ytest))\n",
    "    ypred= np.squeeze(np.asarray(ypred))\n",
    "    total=len(ypred)\n",
    "    accuracy=0\n",
    "    for i in range(0,total):\n",
    "      if ytest[i]==ypred[i]:\n",
    "        accuracy=accuracy+1\n",
    "    acc= accuracy/total\n",
    "    return acc\n",
    "\n",
    "def regressionObjVal(w, X, y):\n",
    "  w=np.matrix(w)\n",
    "  w=w.transpose()\n",
    "  A=np.dot(X,w)\n",
    "  B=np.subtract(y,A)\n",
    "  Bt=B.transpose()\n",
    "  e=np.dot(Bt,B)\n",
    "  E=0.5*e\n",
    "  error=E[0,0]\n",
    "  return error\n",
    "\n",
    "def regressionGradient(w, X, y):\n",
    "  w=np.matrix(w)\n",
    "  w=w.transpose()\n",
    "  A=X.transpose()\n",
    "  B=X\n",
    "  B1=np.dot(A,B)\n",
    "  B2=np.dot(B1,w)\n",
    "  C=np.dot(A,y)\n",
    "  D=B2-C\n",
    "  D= np.squeeze(np.asarray(D))\n",
    "  return D  \n",
    "\n",
    "def logisticObjVal(w, X, y):\n",
    "  n=len(X)\n",
    "  total =0\n",
    "  w=w.reshape(-1,1)\n",
    "  w=w.transpose()\n",
    "  for i in range(0,n):\n",
    "    yi=y[i]\n",
    "    yi= yi[:,np.newaxis]\n",
    "    Xi=X[i]\n",
    "    C=np.dot(-yi,w)\n",
    "    D=np.dot(C,Xi)\n",
    "    p=np.squeeze(np.asarray(D))\n",
    "    e= math.exp(p)\n",
    "    log= math.log(1+e)\n",
    "    total= total+log\n",
    "  loss=total/n\n",
    "  return loss\n",
    "\n",
    "def logisticGradient(w, X, y):\n",
    "  n=len(X)\n",
    "  w=w.transpose()\n",
    "  y= np.squeeze(np.asarray(y))\n",
    "  total =0\n",
    "  for i in range(0,n):\n",
    "    numerator=np.dot(y[i],X[i])\n",
    "    C=np.dot(y[i],w)\n",
    "    D=np.dot(C,X[i])\n",
    "    p=np.squeeze(np.asarray(D))\n",
    "    e= math.exp(p)\n",
    "    di=numerator/(1+e)\n",
    "    total= total+di\n",
    "  de=-total/n\n",
    "  de= np.squeeze(np.asarray(de))\n",
    "  if len(w.shape) == 1:\n",
    "     w = w[:,np.newaxis]\n",
    "  return de\n",
    "  \n",
    "def logisticHessian(w, X, y):\n",
    "  n=len(X)\n",
    "  w=w.transpose()\n",
    "  y= np.squeeze(np.asarray(y))\n",
    "  hessian= np.zeros([len(X[0])])\n",
    "  for i in range(0,n):\n",
    "    A = X[i]\n",
    "    A=A.reshape(-1,1)\n",
    "    C=np.dot(y[i],w)\n",
    "    D=np.dot(C,X[i])\n",
    "    p=np.squeeze(np.asarray(D))\n",
    "    e= math.exp(p)\n",
    "    di=e/(1+e)**2\n",
    "    B=A.transpose()\n",
    "    square=np.dot(A,B)\n",
    "    H=np.dot(di,square)\n",
    "    hessian= hessian+H\n",
    "  if len(w.shape) == 1:\n",
    "        w = w[:,np.newaxis]\n",
    "  return hessian\n",
    "\n",
    "Xtrain,ytrain, Xtest, ytest = pickle.load(open('sample.pickle','rb')) \n",
    "# add intercept\n",
    "Xtrain_i = np.concatenate((np.ones((Xtrain.shape[0],1)), Xtrain), axis=1)\n",
    "Xtest_i = np.concatenate((np.ones((Xtest.shape[0],1)), Xtest), axis=1)\n",
    "\n",
    "args = (Xtrain_i,ytrain)\n",
    "opts = {'maxiter' : 50}    # Preferred value.    \n",
    "w_init = np.zeros((Xtrain_i.shape[1],1))\n",
    "soln = minimize(logisticObjVal, w_init, jac=logisticGradient, hess=logisticHessian, args=args,method='Newton-CG', options=opts)\n",
    "w = np.transpose(np.array(soln.x))\n",
    "w = np.reshape(w,[len(w),1])\n",
    "acc = evaluateLinearModel(w,Xtrain_i,ytrain)\n",
    "print('Logistic Regression Accuracy on train data - %.2f'%acc)\n",
    "acc = evaluateLinearModel(w,Xtest_i,ytest)\n",
    "print('Logistic Regression Accuracy on test data - %.2f'%acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UwEsRtGcyp8w"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOKnumTl8H5Rm7Kjdv47KJ3",
   "name": "HW1_Q1/2/3/4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
